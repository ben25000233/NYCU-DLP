{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bf76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dataloader import LeukemiaLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device('cuda',0)\n",
    "from torch.utils.data import Dataset,DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms,models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c3e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res18_basic_Block(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride = 1):\n",
    "        super(Res18_basic_Block, self).__init__()\n",
    "        \n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.basic(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8b8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self, inchannel, outchannel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=stride, padding=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel * self.expansion, kernel_size=1, stride=1),   \n",
    "            nn.BatchNorm2d(outchannel * self.expansion)\n",
    "        )\n",
    "         \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "    \n",
    "        out = self.basic(x)\n",
    "\n",
    "        out += identity\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb2942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(512, 2, stride=2)  \n",
    "        self.classify = nn.Linear(512, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self, channel, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Res18_basic_Block(self.inchannel, channel, stride))\n",
    "            self.inchannel = channel\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6177735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_50, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,4,6,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca19448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_152, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,8,36,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb79ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_y, label):\n",
    "    pred_y = pred_y.to(device)\n",
    "    label = label.to(device)\n",
    "    correct = pred_y.max(dim=1)[1].eq(label).sum().item()\n",
    "    total = label.shape[0]\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "def save_result(csv_path, predict_result):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['ID'] = df['Path']\n",
    "    new_df[\"label\"] = predict_result\n",
    "    new_df.to_csv(\"./your_student_id_resnet18.csv\", index=False)\n",
    "def plot(a,b,c,d,e,f):\n",
    "    epoch_list = []\n",
    "    for i in range(len(a)):\n",
    "        epoch_list.append(i)\n",
    "\n",
    "    plt.plot(epoch_list, a, label= \"res18_train\")\n",
    "    plt.plot(epoch_list, b, label= \"res18_test\")\n",
    "    plt.plot(epoch_list, c, label= \"res50_train\")\n",
    "    plt.plot(epoch_list, d, label= \"res50_test\")\n",
    "    plt.plot(epoch_list, e, label= \"res152_train\")\n",
    "    plt.plot(epoch_list, f, label= \"res152_test\")\n",
    "    plt.ylim(50, 100)\n",
    "    plt.legend(loc = 4)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(pred_y, label):\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(label, pred_y)\n",
    "    colors = ['white', '#b4c7e7', '#8caad9', '#5a8ed0', '#1974c7']\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    classes = [0, 1] \n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe4fa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader_train, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    counter = 0\n",
    "    for idx,(data,label, path) in enumerate(loader_train):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(data)\n",
    "        mono_loss = loss_fn(pred_y, label)\n",
    "        mono_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += mono_loss\n",
    "        mono_acc = evaluate(pred_y, label)\n",
    "        total_correct += mono_acc\n",
    "        counter+=1\n",
    "\n",
    "    train_loss = total_loss / len(loader_train.dataset)\n",
    "    train_accuracy = total_correct / counter\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def validate(model, loader_test, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,(data,label, path) in enumerate(loader_test):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            label = label.to(device, dtype=torch.long)\n",
    "\n",
    "            pred_y = model(data)\n",
    "            mono_loss = loss_fn(pred_y, label)\n",
    "\n",
    "            total_loss += mono_loss\n",
    "            mono_acc = evaluate(pred_y, label)\n",
    "            total_correct += mono_acc\n",
    "            counter+=1\n",
    "\n",
    "    test_loss = total_loss / len(loader_test.dataset)\n",
    "    test_accuracy = total_correct / counter\n",
    "    return test_loss, test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3319c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, loader_train,loader_test): \n",
    "\n",
    "    model.to(device)\n",
    "    lr = 1e-2\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    best_acc = 0\n",
    "    best_model_wts=None\n",
    "    total_train = [0]\n",
    "    total_test = [0]\n",
    "    epochs = 50\n",
    "    \n",
    "\n",
    "    for epoch in tqdm(range(1, epochs + 1), total=epochs):\n",
    "        train_loss, train_accuracy = train(model, loader_train, optimizer, loss_fn)\n",
    "        total_train.append(train_accuracy)\n",
    "        test_loss, test_accuracy = validate(model, loader_test, loss_fn)\n",
    "        total_test.append(test_accuracy)\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        if test_accuracy>best_acc:\n",
    "            best_evaluated_acc = test_accuracy\n",
    "            best_model_wts=copy.deepcopy(model.state_dict())\n",
    "            FILE = 'resnet_50_state_dict.pt'\n",
    "            torch.save(best_model_wts,FILE)\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_train, total_test, best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d9adca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, weights_path):\n",
    "    weight_file = weights_path\n",
    "    model.load_state_dict(torch.load(weight_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    result = []\n",
    "\n",
    "\n",
    "    with open('result.csv', 'w', newline='') as csvfile:\n",
    "       writer = csv.writer(csvfile)\n",
    "       writer.writerow(['ID', 'label'])\n",
    "       with torch.no_grad():\n",
    "           for idx,(data, path) in enumerate(test_data):\n",
    "               data = data.to(device, dtype=torch.float)\n",
    "               pred_y = model(data)\n",
    "               outputs = pred_y.max(dim=1)[1]\n",
    "               output = outputs.tolist()\n",
    "               path = \".\"+str(path)[2:-3]\n",
    "               writer.writerow([path, output[0]])\n",
    "               result += output   \n",
    "    \n",
    "    return result\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "15b11af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_test(model, loader_test, weights_path):\n",
    "    weight_file = weights_path\n",
    "    model.load_state_dict(torch.load(weight_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    result = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx,(data, label, path) in tqdm(enumerate(loader_test), total = len(loader_test)):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            pred_y = model(data)\n",
    "            outputs = pred_y.max(dim=1)[1]\n",
    "            output = outputs.tolist()\n",
    "            result += output  \n",
    "            label = label.tolist()\n",
    "            labels += label\n",
    "\n",
    "    return labels, result\n",
    "    \n",
    "\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d9b337fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 7995 images...\n",
      "> Found 1599 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 30\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[39m\u001b[39m\u001b[39m'''\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[39mneural_network_18 = ResNet_18()\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[39mres18_train,res18_test, res18_weights= train_and_test(neural_network_18, loader_train,loader_valid)\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[39mf.close()\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[39m'''\u001b[39;00m\n\u001b[1;32m     29\u001b[0m neural_network_50 \u001b[39m=\u001b[39m ResNet_50()\n\u001b[0;32m---> 30\u001b[0m res50_train,res50_test, res50_weights\u001b[39m=\u001b[39m train_and_test(neural_network_50, loader_train,loader_valid)\n\u001b[1;32m     31\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresnet50_train max acc：\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(res50_train)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     32\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mresnet50_test max acc：\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mmax\u001b[39m(res50_test)\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, loader_train, loader_test)\u001b[0m\n\u001b[1;32m     12\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m50\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m tqdm(\u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, epochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m), total\u001b[39m=\u001b[39mepochs):\n\u001b[0;32m---> 16\u001b[0m     train_loss, train_accuracy \u001b[39m=\u001b[39m train(model, loader_train, optimizer, loss_fn)\n\u001b[1;32m     17\u001b[0m     total_train\u001b[39m.\u001b[39mappend(train_accuracy)\n\u001b[1;32m     18\u001b[0m     test_loss, test_accuracy \u001b[39m=\u001b[39m validate(model, loader_test, loss_fn)\n",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, loader_train, optimizer, loss_fn)\u001b[0m\n\u001b[1;32m      8\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mlong)\n\u001b[1;32m     10\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> 11\u001b[0m pred_y \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     12\u001b[0m mono_loss \u001b[39m=\u001b[39m loss_fn(pred_y, label)\n\u001b[1;32m     13\u001b[0m mono_loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[5], line 39\u001b[0m, in \u001b[0;36mResNet_50.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 39\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconv1(x)\n\u001b[1;32m     40\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer1(out)\n\u001b[1;32m     41\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:463\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 463\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/conv.py:459\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    456\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    457\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    458\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> 459\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    460\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 24\n",
    "    \n",
    "    dataset_train=LeukemiaLoader(root='new_dataset/train/',mode='train')\n",
    "    loader_train=DataLoader(dataset=dataset_train, batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "   \n",
    "    dataset_valid=LeukemiaLoader(root='new_dataset/valid/',mode='valid')\n",
    "    loader_valid=DataLoader(dataset=dataset_valid,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "\n",
    "    \n",
    "\n",
    "    '''\n",
    "    neural_network_18 = ResNet_18()\n",
    "    res18_train,res18_test, res18_weights= train_and_test(neural_network_18, loader_train,loader_valid)\n",
    "    print(f\"resnet18 max acc：{max(res18_train)}\")\n",
    "    print(f\"resnet18_test max acc：{max(res18_test)}\")\n",
    "    FILE = 'resnet_18_all_state_dict.pt'\n",
    "    torch.save(res18_weights,FILE)\n",
    "    a = str(res18_train)\n",
    "    b = str(res18_test)\n",
    "    f = open('resnet18_train.txt','w')\n",
    "    f.write(a)\n",
    "    f.close()\n",
    "    f = open('resnet18_test.txt','w')\n",
    "    f.write(b)\n",
    "    f.close()\n",
    "    '''\n",
    "    \n",
    "    neural_network_50 = ResNet_50()\n",
    "    res50_train,res50_test, res50_weights= train_and_test(neural_network_50, loader_train,loader_valid)\n",
    "    print(f\"resnet50_train max acc：{max(res50_train)}\")\n",
    "    print(f\"resnet50_test max acc：{max(res50_test)}\")\n",
    "    FILE = 'resnet_50_all_state_dict.pt'\n",
    "    torch.save(res50_weights,FILE)\n",
    "    a = str(res50_train)\n",
    "    b = str(res50_test)\n",
    "    f = open('resnet50_train.txt','w')\n",
    "    f.write(a)\n",
    "    f.close()\n",
    "    f = open('resnet50_test.txt','w')\n",
    "    f.write(b)\n",
    "    f.close()\n",
    "    \n",
    "   \n",
    "    '''\n",
    "    neural_network_152 = ResNet_152()\n",
    "    res152_train,res152_test, res152_weights= train_and_test(neural_network_152, loader_train,loader_valid)\n",
    "    print(f\"resnet152_train max acc：{max(res152_train)}\")\n",
    "    print(f\"resnet152_test max acc：{max(res152_test)}\")\n",
    "    FILE = 'resnet_152_all_state_dict.pt'\n",
    "    torch.save(res152_weights,FILE)\n",
    "    a = str(res152_train)\n",
    "    b = str(res152_test)\n",
    "    f = open('resnet152_train.txt','w')\n",
    "    f.write(a)\n",
    "    f.close()\n",
    "    f = open('resnet152_test.txt','w')\n",
    "    f.write(b)\n",
    "    f.close()\n",
    "    #plot(res18_train,res18_test,res50_train,res50_test, res152_train,res152_test)\n",
    "    '''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93e4406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\ndataset_test=LeukemiaLoader(root='new_dataset/test/',mode='test50')\\nloader_test=DataLoader(dataset=dataset_test,batch_size=1,shuffle=False,num_workers=4)\\n\\nres50 = ResNet_50()\\nresult = test(res50, loader_test, 'resnet_50_state_dict.pt')\\nprint(result)\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test=LeukemiaLoader(root='new_dataset/test/',mode='test50')\n",
    "loader_test=DataLoader(dataset=dataset_test,batch_size=1,shuffle=False,num_workers=4)\n",
    "\n",
    "res50 = ResNet_50()\n",
    "result = test(res50, loader_test, 'resnet_50_state_dict.pt')\n",
    "print(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c38d78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 7995 images...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 904/7995 [00:12<01:37, 73.04it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m loader_train\u001b[39m=\u001b[39mDataLoader(dataset\u001b[39m=\u001b[39mdataset_train, batch_size\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m      4\u001b[0m neural_network_18 \u001b[39m=\u001b[39m ResNet_18()\n\u001b[0;32m----> 5\u001b[0m labels, result \u001b[39m=\u001b[39m tv_test(neural_network_18, loader_train, \u001b[39m\"\u001b[39;49m\u001b[39mresnet_18_all_state_dict.pt\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m      6\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mRestNet18\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      7\u001b[0m plot_confusion_matrix(labels, result)\n",
      "Cell \u001b[0;32mIn[11], line 12\u001b[0m, in \u001b[0;36mtv_test\u001b[0;34m(model, loader_test, weights_path)\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfor\u001b[39;00m idx,(data, label, path) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(loader_test), total \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(loader_test)):\n\u001b[1;32m     11\u001b[0m     data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device, dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat)\n\u001b[0;32m---> 12\u001b[0m     pred_y \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     13\u001b[0m     outputs \u001b[39m=\u001b[39m pred_y\u001b[39m.\u001b[39mmax(dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m1\u001b[39m]\n\u001b[1;32m     14\u001b[0m     output \u001b[39m=\u001b[39m outputs\u001b[39m.\u001b[39mtolist()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[4], line 32\u001b[0m, in \u001b[0;36mResNet_18.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     30\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer2(out)\n\u001b[1;32m     31\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayer3(out)\n\u001b[0;32m---> 32\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlayer4(out)\n\u001b[1;32m     33\u001b[0m out \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mAdaptiveAvgPool2d((\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m))(out)\n\u001b[1;32m     34\u001b[0m out \u001b[39m=\u001b[39m out\u001b[39m.\u001b[39mview(out\u001b[39m.\u001b[39msize(\u001b[39m0\u001b[39m), \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/container.py:204\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    203\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> 204\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    205\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1194\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1190\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1191\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1192\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1195\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1196\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mRes18_basic_Block.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> 23\u001b[0m     out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbasic(x)\n\u001b[1;32m     24\u001b[0m     out \u001b[39m=\u001b[39m out \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshortcut(x)\n\u001b[1;32m     25\u001b[0m     out \u001b[39m=\u001b[39m nn\u001b[39m.\u001b[39mReLU()(out)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:1256\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1253\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_is_full_backward_hook\u001b[39m\u001b[39m'\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1254\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_full_backward_hook \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1256\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, name: \u001b[39mstr\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[Tensor, \u001b[39m'\u001b[39m\u001b[39mModule\u001b[39m\u001b[39m'\u001b[39m]:\n\u001b[1;32m   1257\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m:\n\u001b[1;32m   1258\u001b[0m         _parameters \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__dict__\u001b[39m[\u001b[39m'\u001b[39m\u001b[39m_parameters\u001b[39m\u001b[39m'\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "'''\n",
    "dataset_train=LeukemiaLoader(root='new_dataset/train/',mode='train')\n",
    "loader_train=DataLoader(dataset=dataset_train, batch_size=1,shuffle=False,num_workers=4)\n",
    "\n",
    "neural_network_18 = ResNet_18()\n",
    "labels, result = tv_test(neural_network_18, loader_train, \"resnet_18_all_state_dict.pt\")\n",
    "print(\"RestNet18\")\n",
    "plot_confusion_matrix(labels, result)\n",
    "\n",
    "neural_network_50 = ResNet_50()\n",
    "labels, result = tv_test(neural_network_50, loader_train, \"resnet_50_all_state_dict.pt\")\n",
    "print(\"RestNet50\")\n",
    "plot_confusion_matrix(labels, result)\n",
    "\n",
    "neural_network_152 = ResNet_152()\n",
    "labels, result = tv_test(neural_network_152, loader_train, \"resnet_152_all_state_dict.pt\")\n",
    "print(\"RestNet152\")\n",
    "plot_confusion_matrix(labels, result)\n",
    "'''\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
