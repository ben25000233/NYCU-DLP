{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bf76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dataloader import LeukemiaLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device('cuda',0)\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c3e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res18_basic_Block(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride = 1):\n",
    "        super(Res18_basic_Block, self).__init__()\n",
    "        \n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.basic(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8b8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self, inchannel, outchannel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=stride, padding=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel * self.expansion, kernel_size=1, stride=1),   \n",
    "            nn.BatchNorm2d(outchannel * self.expansion)\n",
    "        )\n",
    "         \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "    \n",
    "        out = self.basic(x)\n",
    "\n",
    "        out += identity\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb2942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(512, 2, stride=2)  \n",
    "        self.classify = nn.Linear(512, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self, channel, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Res18_basic_Block(self.inchannel, channel, stride))\n",
    "            self.inchannel = channel\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6177735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_50, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,4,6,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca19448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_152, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,8,36,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4fa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader_train, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    counter = 0\n",
    "    for idx,(data,label, path) in enumerate(loader_train):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(data)\n",
    "        mono_loss = loss_fn(pred_y, label)\n",
    "        mono_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += mono_loss\n",
    "        mono_acc = evaluate(pred_y, label)\n",
    "        total_correct += mono_acc\n",
    "        counter+=1\n",
    "\n",
    "    train_loss = total_loss / len(loader_train.dataset)\n",
    "    train_accuracy = total_correct / counter\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def test(model, loader_test, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,(data,label, path) in enumerate(loader_test):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            label = label.to(device, dtype=torch.long)\n",
    "\n",
    "            pred_y = model(data)\n",
    "            mono_loss = loss_fn(pred_y, label)\n",
    "\n",
    "            total_loss += mono_loss\n",
    "            mono_acc = evaluate(pred_y, label)\n",
    "            total_correct += mono_acc\n",
    "            counter+=1\n",
    "\n",
    "    test_loss = total_loss / len(loader_test.dataset)\n",
    "    test_accuracy = total_correct / counter\n",
    "    return test_loss, test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3319c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, loader_train,loader_test): \n",
    "    model = model()\n",
    "    model.to(device)\n",
    "    lr = 1e-2\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "\n",
    "    total_train = [0]\n",
    "    total_test = [0]\n",
    "    epochs = 100\n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_accuracy = train(model, loader_train, optimizer, loss_fn)\n",
    "        total_train.append(train_accuracy)\n",
    "        test_loss, test_accuracy = test(model, loader_test, loss_fn)\n",
    "        total_test.append(test_accuracy)\n",
    "        if(epoch%10 == 0):\n",
    "            print(f\"Epoch {epoch}\")\n",
    "            print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "            print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_train, total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4a5c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_y, label):\n",
    "    pred_y = pred_y.to(device)\n",
    "    label = label.to(device)\n",
    "    correct = pred_y.max(dim=1)[1].eq(label).sum().item()\n",
    "    total = label.shape[0]\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "def save_result(csv_path, predict_result):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['ID'] = df['Path']\n",
    "    new_df[\"label\"] = predict_result\n",
    "    new_df.to_csv(\"./your_student_id_resnet18.csv\", index=False)\n",
    "def plot(resnet_train,resnet_test):\n",
    "    epoch_list = []\n",
    "    for i in range(len(resnet_train)):\n",
    "        epoch_list.append(i)\n",
    "\n",
    "    plt.plot(epoch_list, resnet_train, label= \"res_train\")\n",
    "    plt.plot(epoch_list, resnet_test, label= \"res_test\")\n",
    "    plt.ylim(50, 100)\n",
    "    plt.legend(loc = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9b337fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 7995 images...\n",
      "> Found 1599 images...\n",
      "> Found 1067 images...\n",
      "Epoch 1\n",
      "Train Loss: 0.0031, Train Accuracy: 67.43%\n",
      "Test Loss: 0.0354, Test Accuracy: 36.51%\n",
      "Epoch 2\n",
      "Train Loss: 0.0030, Train Accuracy: 67.76%\n",
      "Test Loss: 0.0144, Test Accuracy: 71.05%\n",
      "Epoch 3\n",
      "Train Loss: 0.0030, Train Accuracy: 72.04%\n",
      "Test Loss: 0.0142, Test Accuracy: 65.79%\n",
      "Epoch 4\n",
      "Train Loss: 0.0026, Train Accuracy: 74.34%\n",
      "Test Loss: 0.0439, Test Accuracy: 39.80%\n",
      "Epoch 5\n",
      "Train Loss: 0.0024, Train Accuracy: 75.66%\n",
      "Test Loss: 0.0166, Test Accuracy: 66.45%\n",
      "Epoch 6\n",
      "Train Loss: 0.0027, Train Accuracy: 74.01%\n",
      "Test Loss: 0.0142, Test Accuracy: 73.68%\n",
      "Epoch 7\n",
      "Train Loss: 0.0023, Train Accuracy: 78.29%\n",
      "Test Loss: 0.0280, Test Accuracy: 70.72%\n",
      "Epoch 8\n",
      "Train Loss: 0.0023, Train Accuracy: 76.32%\n",
      "Test Loss: 0.0322, Test Accuracy: 49.67%\n",
      "Epoch 9\n",
      "Train Loss: 0.0024, Train Accuracy: 78.29%\n",
      "Test Loss: 0.0103, Test Accuracy: 81.58%\n",
      "Epoch 10\n",
      "Train Loss: 0.0023, Train Accuracy: 76.64%\n",
      "Test Loss: 0.0112, Test Accuracy: 78.62%\n",
      "Epoch 11\n",
      "Train Loss: 0.0023, Train Accuracy: 78.29%\n",
      "Test Loss: 0.0232, Test Accuracy: 48.36%\n",
      "Epoch 12\n",
      "Train Loss: 0.0021, Train Accuracy: 81.25%\n",
      "Test Loss: 0.0113, Test Accuracy: 82.24%\n",
      "Epoch 13\n",
      "Train Loss: 0.0021, Train Accuracy: 78.62%\n",
      "Test Loss: 0.0104, Test Accuracy: 83.22%\n",
      "Epoch 14\n",
      "Train Loss: 0.0019, Train Accuracy: 83.22%\n",
      "Test Loss: 0.0098, Test Accuracy: 83.22%\n",
      "Epoch 15\n",
      "Train Loss: 0.0022, Train Accuracy: 79.93%\n",
      "Test Loss: 0.0118, Test Accuracy: 74.67%\n",
      "Epoch 16\n",
      "Train Loss: 0.0021, Train Accuracy: 82.24%\n",
      "Test Loss: 0.0109, Test Accuracy: 79.93%\n",
      "Epoch 17\n",
      "Train Loss: 0.0019, Train Accuracy: 83.22%\n",
      "Test Loss: 0.0100, Test Accuracy: 81.58%\n",
      "Epoch 18\n",
      "Train Loss: 0.0021, Train Accuracy: 81.58%\n",
      "Test Loss: 0.0103, Test Accuracy: 81.58%\n",
      "Epoch 19\n",
      "Train Loss: 0.0020, Train Accuracy: 83.22%\n",
      "Test Loss: 0.0104, Test Accuracy: 81.58%\n",
      "Epoch 20\n",
      "Train Loss: 0.0018, Train Accuracy: 84.21%\n",
      "Test Loss: 0.0105, Test Accuracy: 82.24%\n",
      "Epoch 21\n",
      "Train Loss: 0.0020, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0187, Test Accuracy: 74.34%\n",
      "Epoch 22\n",
      "Train Loss: 0.0018, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0101, Test Accuracy: 82.24%\n",
      "Epoch 23\n",
      "Train Loss: 0.0018, Train Accuracy: 83.88%\n",
      "Test Loss: 0.0097, Test Accuracy: 82.89%\n",
      "Epoch 24\n",
      "Train Loss: 0.0019, Train Accuracy: 79.93%\n",
      "Test Loss: 0.0098, Test Accuracy: 81.58%\n",
      "Epoch 25\n",
      "Train Loss: 0.0016, Train Accuracy: 88.16%\n",
      "Test Loss: 0.0102, Test Accuracy: 79.93%\n",
      "Epoch 26\n",
      "Train Loss: 0.0019, Train Accuracy: 83.22%\n",
      "Test Loss: 0.0097, Test Accuracy: 81.58%\n",
      "Epoch 27\n",
      "Train Loss: 0.0018, Train Accuracy: 86.18%\n",
      "Test Loss: 0.0096, Test Accuracy: 83.55%\n",
      "Epoch 28\n",
      "Train Loss: 0.0018, Train Accuracy: 82.24%\n",
      "Test Loss: 0.0101, Test Accuracy: 82.24%\n",
      "Epoch 29\n",
      "Train Loss: 0.0016, Train Accuracy: 85.86%\n",
      "Test Loss: 0.0105, Test Accuracy: 80.26%\n",
      "Epoch 30\n",
      "Train Loss: 0.0017, Train Accuracy: 83.88%\n",
      "Test Loss: 0.0099, Test Accuracy: 80.26%\n",
      "Epoch 31\n",
      "Train Loss: 0.0017, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0097, Test Accuracy: 82.24%\n",
      "Epoch 32\n",
      "Train Loss: 0.0017, Train Accuracy: 84.87%\n",
      "Test Loss: 0.0105, Test Accuracy: 80.59%\n",
      "Epoch 33\n",
      "Train Loss: 0.0016, Train Accuracy: 83.88%\n",
      "Test Loss: 0.0099, Test Accuracy: 83.22%\n",
      "Epoch 34\n",
      "Train Loss: 0.0018, Train Accuracy: 82.24%\n",
      "Test Loss: 0.0099, Test Accuracy: 83.88%\n",
      "Epoch 35\n",
      "Train Loss: 0.0017, Train Accuracy: 85.86%\n",
      "Test Loss: 0.0097, Test Accuracy: 83.22%\n",
      "Epoch 36\n",
      "Train Loss: 0.0017, Train Accuracy: 83.88%\n",
      "Test Loss: 0.0102, Test Accuracy: 82.57%\n",
      "Epoch 37\n",
      "Train Loss: 0.0017, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0100, Test Accuracy: 81.58%\n",
      "Epoch 38\n",
      "Train Loss: 0.0018, Train Accuracy: 85.86%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.24%\n",
      "Epoch 39\n",
      "Train Loss: 0.0017, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0097, Test Accuracy: 82.57%\n",
      "Epoch 40\n",
      "Train Loss: 0.0017, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0096, Test Accuracy: 82.24%\n",
      "Epoch 41\n",
      "Train Loss: 0.0018, Train Accuracy: 83.88%\n",
      "Test Loss: 0.0100, Test Accuracy: 81.91%\n",
      "Epoch 42\n",
      "Train Loss: 0.0016, Train Accuracy: 84.87%\n",
      "Test Loss: 0.0100, Test Accuracy: 81.91%\n",
      "Epoch 43\n",
      "Train Loss: 0.0016, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0099, Test Accuracy: 81.25%\n",
      "Epoch 44\n",
      "Train Loss: 0.0017, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0101, Test Accuracy: 82.89%\n",
      "Epoch 45\n",
      "Train Loss: 0.0017, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0103, Test Accuracy: 80.26%\n",
      "Epoch 46\n",
      "Train Loss: 0.0016, Train Accuracy: 87.50%\n",
      "Test Loss: 0.0100, Test Accuracy: 81.58%\n",
      "Epoch 47\n",
      "Train Loss: 0.0017, Train Accuracy: 86.51%\n",
      "Test Loss: 0.0098, Test Accuracy: 83.88%\n",
      "Epoch 48\n",
      "Train Loss: 0.0016, Train Accuracy: 83.88%\n",
      "Test Loss: 0.0104, Test Accuracy: 82.89%\n",
      "Epoch 49\n",
      "Train Loss: 0.0016, Train Accuracy: 85.86%\n",
      "Test Loss: 0.0098, Test Accuracy: 81.91%\n",
      "Epoch 50\n",
      "Train Loss: 0.0018, Train Accuracy: 81.25%\n",
      "Test Loss: 0.0099, Test Accuracy: 81.58%\n",
      "Epoch 51\n",
      "Train Loss: 0.0016, Train Accuracy: 87.17%\n",
      "Test Loss: 0.0098, Test Accuracy: 81.91%\n",
      "Epoch 52\n",
      "Train Loss: 0.0016, Train Accuracy: 85.86%\n",
      "Test Loss: 0.0099, Test Accuracy: 83.55%\n",
      "Epoch 53\n",
      "Train Loss: 0.0015, Train Accuracy: 88.16%\n",
      "Test Loss: 0.0098, Test Accuracy: 83.55%\n",
      "Epoch 54\n",
      "Train Loss: 0.0017, Train Accuracy: 84.21%\n",
      "Test Loss: 0.0102, Test Accuracy: 81.25%\n",
      "Epoch 55\n",
      "Train Loss: 0.0015, Train Accuracy: 87.17%\n",
      "Test Loss: 0.0100, Test Accuracy: 82.57%\n",
      "Epoch 56\n",
      "Train Loss: 0.0016, Train Accuracy: 87.17%\n",
      "Test Loss: 0.0097, Test Accuracy: 83.22%\n",
      "Epoch 57\n",
      "Train Loss: 0.0017, Train Accuracy: 84.21%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.57%\n",
      "Epoch 58\n",
      "Train Loss: 0.0016, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.24%\n",
      "Epoch 59\n",
      "Train Loss: 0.0017, Train Accuracy: 86.18%\n",
      "Test Loss: 0.0099, Test Accuracy: 83.55%\n",
      "Epoch 60\n",
      "Train Loss: 0.0017, Train Accuracy: 84.54%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.89%\n",
      "Epoch 61\n",
      "Train Loss: 0.0018, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0094, Test Accuracy: 84.21%\n",
      "Epoch 62\n",
      "Train Loss: 0.0017, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0105, Test Accuracy: 78.95%\n",
      "Epoch 63\n",
      "Train Loss: 0.0015, Train Accuracy: 86.18%\n",
      "Test Loss: 0.0104, Test Accuracy: 81.58%\n",
      "Epoch 64\n",
      "Train Loss: 0.0017, Train Accuracy: 82.89%\n",
      "Test Loss: 0.0096, Test Accuracy: 82.57%\n",
      "Epoch 65\n",
      "Train Loss: 0.0016, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0099, Test Accuracy: 82.24%\n",
      "Epoch 66\n",
      "Train Loss: 0.0019, Train Accuracy: 81.58%\n",
      "Test Loss: 0.0099, Test Accuracy: 81.58%\n",
      "Epoch 67\n",
      "Train Loss: 0.0015, Train Accuracy: 86.84%\n",
      "Test Loss: 0.0103, Test Accuracy: 79.93%\n",
      "Epoch 68\n",
      "Train Loss: 0.0017, Train Accuracy: 82.57%\n",
      "Test Loss: 0.0101, Test Accuracy: 79.93%\n",
      "Epoch 69\n",
      "Train Loss: 0.0015, Train Accuracy: 88.49%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.89%\n",
      "Epoch 70\n",
      "Train Loss: 0.0017, Train Accuracy: 86.84%\n",
      "Test Loss: 0.0098, Test Accuracy: 83.55%\n",
      "Epoch 71\n",
      "Train Loss: 0.0017, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0099, Test Accuracy: 81.91%\n",
      "Epoch 72\n",
      "Train Loss: 0.0016, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0102, Test Accuracy: 82.24%\n",
      "Epoch 73\n",
      "Train Loss: 0.0017, Train Accuracy: 84.21%\n",
      "Test Loss: 0.0101, Test Accuracy: 81.25%\n",
      "Epoch 74\n",
      "Train Loss: 0.0017, Train Accuracy: 84.21%\n",
      "Test Loss: 0.0103, Test Accuracy: 80.92%\n",
      "Epoch 75\n",
      "Train Loss: 0.0015, Train Accuracy: 84.87%\n",
      "Test Loss: 0.0099, Test Accuracy: 79.93%\n",
      "Epoch 76\n",
      "Train Loss: 0.0016, Train Accuracy: 86.51%\n",
      "Test Loss: 0.0103, Test Accuracy: 79.61%\n",
      "Epoch 77\n",
      "Train Loss: 0.0016, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0092, Test Accuracy: 84.87%\n",
      "Epoch 78\n",
      "Train Loss: 0.0017, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0099, Test Accuracy: 83.22%\n",
      "Epoch 79\n",
      "Train Loss: 0.0019, Train Accuracy: 80.92%\n",
      "Test Loss: 0.0096, Test Accuracy: 84.21%\n",
      "Epoch 80\n",
      "Train Loss: 0.0017, Train Accuracy: 84.54%\n",
      "Test Loss: 0.0102, Test Accuracy: 79.28%\n",
      "Epoch 81\n",
      "Train Loss: 0.0018, Train Accuracy: 83.22%\n",
      "Test Loss: 0.0104, Test Accuracy: 81.91%\n",
      "Epoch 82\n",
      "Train Loss: 0.0016, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.24%\n",
      "Epoch 83\n",
      "Train Loss: 0.0016, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.89%\n",
      "Epoch 84\n",
      "Train Loss: 0.0015, Train Accuracy: 87.83%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.24%\n",
      "Epoch 85\n",
      "Train Loss: 0.0016, Train Accuracy: 88.16%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.89%\n",
      "Epoch 86\n",
      "Train Loss: 0.0017, Train Accuracy: 84.54%\n",
      "Test Loss: 0.0100, Test Accuracy: 81.25%\n",
      "Epoch 87\n",
      "Train Loss: 0.0016, Train Accuracy: 83.55%\n",
      "Test Loss: 0.0096, Test Accuracy: 81.58%\n",
      "Epoch 88\n",
      "Train Loss: 0.0015, Train Accuracy: 88.16%\n",
      "Test Loss: 0.0106, Test Accuracy: 79.28%\n",
      "Epoch 89\n",
      "Train Loss: 0.0017, Train Accuracy: 85.86%\n",
      "Test Loss: 0.0101, Test Accuracy: 79.93%\n",
      "Epoch 90\n",
      "Train Loss: 0.0017, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0097, Test Accuracy: 82.24%\n",
      "Epoch 91\n",
      "Train Loss: 0.0015, Train Accuracy: 87.83%\n",
      "Test Loss: 0.0101, Test Accuracy: 80.92%\n",
      "Epoch 92\n",
      "Train Loss: 0.0016, Train Accuracy: 86.18%\n",
      "Test Loss: 0.0096, Test Accuracy: 82.89%\n",
      "Epoch 93\n",
      "Train Loss: 0.0016, Train Accuracy: 84.54%\n",
      "Test Loss: 0.0104, Test Accuracy: 80.26%\n",
      "Epoch 94\n",
      "Train Loss: 0.0016, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0106, Test Accuracy: 82.57%\n",
      "Epoch 95\n",
      "Train Loss: 0.0016, Train Accuracy: 85.20%\n",
      "Test Loss: 0.0104, Test Accuracy: 81.25%\n",
      "Epoch 96\n",
      "Train Loss: 0.0016, Train Accuracy: 86.18%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.24%\n",
      "Epoch 97\n",
      "Train Loss: 0.0018, Train Accuracy: 82.89%\n",
      "Test Loss: 0.0108, Test Accuracy: 79.93%\n",
      "Epoch 98\n",
      "Train Loss: 0.0016, Train Accuracy: 86.51%\n",
      "Test Loss: 0.0104, Test Accuracy: 81.25%\n",
      "Epoch 99\n",
      "Train Loss: 0.0016, Train Accuracy: 87.50%\n",
      "Test Loss: 0.0098, Test Accuracy: 82.89%\n",
      "Epoch 100\n",
      "Train Loss: 0.0016, Train Accuracy: 85.53%\n",
      "Test Loss: 0.0109, Test Accuracy: 78.95%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 21\u001b[0m\n\u001b[1;32m     19\u001b[0m res18_train,res18_test\u001b[39m=\u001b[39m train_and_test(ResNet_18, loader_train,loader_valid)\n\u001b[1;32m     20\u001b[0m FILE \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mresnet_18_state_dict.pt\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m---> 21\u001b[0m torch\u001b[39m.\u001b[39msave(model\u001b[39m.\u001b[39mstate_dict(), FILE)\n\u001b[1;32m     23\u001b[0m neural_network_50 \u001b[39m=\u001b[39m ResNet_50()\n\u001b[1;32m     24\u001b[0m res50_train,res50_test\u001b[39m=\u001b[39m train_and_test(ResNet_50, loader_train,loader_valid)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 8\n",
    "    \n",
    "    sampler = SubsetRandomSampler(range(1000))\n",
    "    \n",
    "    dataset_train=LeukemiaLoader(root='new_dataset/train/',mode='train')\n",
    "    loader_train=DataLoader(dataset=dataset_train, sampler = sampler, batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "   \n",
    "    dataset_valid=LeukemiaLoader(root='new_dataset/valid/',mode='valid')\n",
    "    loader_valid=DataLoader(dataset=dataset_valid, sampler = sampler,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "\n",
    "    dataset_test=LeukemiaLoader(root='new_dataset/test/',mode='test')\n",
    "    loader_test=DataLoader(dataset=dataset_test,sampler = sampler,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "    \n",
    "\n",
    "    \n",
    "    neural_network_18 = ResNet_18()\n",
    "    res18_train,res18_test= train_and_test(ResNet_18, loader_train,loader_valid)\n",
    "    print(f\"resnet18 max acc：{max(res18_train)}\")\n",
    "    print(f\"resnet18_test max acc：{max(res18_test)}\")\n",
    "    plot(res18_train,res18_test)\n",
    "    FILE = 'resnet_18_state_dict.pt'\n",
    "    torch.save(neural_network_18.state_dict(), FILE)\n",
    "\n",
    "    neural_network_50 = ResNet_50()\n",
    "    res50_train,res50_test= train_and_test(ResNet_50, loader_train,loader_valid)\n",
    "    print(f\"resnet50_train max acc：{max(res50_train)}\")\n",
    "    print(f\"resnet50_test max acc：{max(res50_test)}\")\n",
    "    plot(res50_train,res50_test)\n",
    "    FILE = 'resnet_50_state_dict.pt'\n",
    "    torch.save(neural_network_50.state_dict(), FILE)\n",
    "\n",
    "    neural_network_152 = ResNet_152()\n",
    "    res152_train,res152_test= train_and_test(ResNet_152, loader_train,loader_valid)\n",
    "    print(f\"resnet152_train max acc：{max(res152_train)}\")\n",
    "    print(f\"resnet152_test max acc：{max(res152_test)}\")\n",
    "    plot(res152_train,res152_test)\n",
    "    FILE = 'resnet_152_state_dict.pt'\n",
    "    torch.save(neural_network_152.state_dict(), FILE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ec800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd99857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
