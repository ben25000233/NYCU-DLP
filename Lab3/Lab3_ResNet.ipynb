{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e2bf76e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "from dataloader import LeukemiaLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device('cuda',0)\n",
    "from torch.utils.data import Dataset,DataLoader\n",
    "from torchvision import transforms,models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import copy\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "21c3e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res18_basic_Block(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride = 1):\n",
    "        super(Res18_basic_Block, self).__init__()\n",
    "        \n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.basic(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ac8b8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self, inchannel, outchannel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=stride, padding=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel * self.expansion, kernel_size=1, stride=1),   \n",
    "            nn.BatchNorm2d(outchannel * self.expansion)\n",
    "        )\n",
    "         \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "    \n",
    "        out = self.basic(x)\n",
    "\n",
    "        out += identity\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fb2942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(512, 2, stride=2)  \n",
    "        self.classify = nn.Linear(512, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self, channel, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Res18_basic_Block(self.inchannel, channel, stride))\n",
    "            self.inchannel = channel\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e6177735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_50, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,4,6,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ca19448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_152, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,8,36,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe4fa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, loader_train,loader_test):   \n",
    "    lr = 1e-2        \n",
    "    loss = torch.nn.CrossEntropyLoss()\n",
    "    total_train = [0]\n",
    "    total_test = [0]\n",
    "\n",
    "    Epochs = 10     \n",
    "    model=model()\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    for epoch in range(1, Epochs+1):\n",
    "        print(epoch)\n",
    "        model.train()\n",
    "        all_loss = 0\n",
    "        all_acc = 0\n",
    "        counter = 0\n",
    "        print(\"in train\")\n",
    "        for idx,(data,label, path) in enumerate(loader_train):\n",
    "            counter+=1\n",
    "            data=data.to(device,dtype=torch.float)\n",
    "            #print(data)\n",
    "            #print(label)\n",
    "            #print(u)\n",
    "            label=label.to(device,dtype=torch.long)\n",
    "            pred_y = model(data)\n",
    "            mono_loss = loss(pred_y, label)\n",
    "            all_loss += mono_loss\n",
    "            mono_acc = evaluate(pred_y, label)\n",
    "            all_acc += mono_acc\n",
    "            optimizer.zero_grad()\n",
    "            mono_loss.backward() \n",
    "            optimizer.step()  \n",
    "        acc = all_acc/counter\n",
    "        total_train.append(acc)\n",
    "        print(f\"Epoch: {epoch}, Loss: {all_loss/len(loader_train.dataset)}, Accuracy: {acc:.2f}%\")\n",
    "        print(\"in test\")    \n",
    "        #test    \n",
    "        model.eval()\n",
    "        all_acc = 0\n",
    "        counter = 0\n",
    "        for idx,(data,label, path) in enumerate(loader_test):\n",
    "            counter+=1\n",
    "            data=data.to(device,dtype=torch.float)\n",
    "            label=label.to(device,dtype=torch.long)\n",
    "            pred_y = model(data)\n",
    "            mono_acc = evaluate(pred_y, label)\n",
    "            all_acc+=mono_acc\n",
    "        acc = all_acc/counter    \n",
    "        total_test.append(acc)\n",
    "        print(f\"Test Accuracy: {acc:.2f}%\")\n",
    "\n",
    "        print(\"out test\")    \n",
    "\n",
    "    return total_train, total_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b4a5c2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_y, label):\n",
    "    pred_y = pred_y.to(device)\n",
    "    label = label.to(device)\n",
    "    correct = pred_y.max(dim=1)[1].eq(label).sum().item()\n",
    "    total = label.shape[0]\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "def save_result(csv_path, predict_result):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    new_df = pd.DataFrame()\n",
    "    new_df['ID'] = df['Path']\n",
    "    new_df[\"label\"] = predict_result\n",
    "    new_df.to_csv(\"./your_student_id_resnet18.csv\", index=False)\n",
    "def plot(res18_train,res18_test, res50_train,res50_test, res152_train,res152_test):\n",
    "    epoch_list = []\n",
    "    for i in range(len(res18_train)):\n",
    "        epoch_list.append(i)\n",
    "\n",
    "    plt.plot(epoch_list, res18_train, label= \"res18_train\")\n",
    "    plt.plot(epoch_list, res18_test, label= \"res18_test\")\n",
    "    plt.plot(epoch_list, res50_train, label= \"res50_train\")\n",
    "    plt.plot(epoch_list, res50_test, label= \"res50_test\")\n",
    "    plt.plot(epoch_list, res152_train, label = \"res152_train\")\n",
    "    plt.plot(epoch_list, res152_test, label = \"res152_test\")\n",
    "    plt.ylim(50, 100)\n",
    "    plt.legend(loc = 4)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9b337fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Found 7995 images...\n",
      "> Found 1599 images...\n",
      "> Found 1067 images...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "in train\n",
      "Epoch: 1, Loss: 0.13715076446533203, Accuracy: 74.04%\n",
      "in test\n",
      "Test Accuracy: 72.67%\n",
      "out test\n",
      "2\n",
      "in train\n",
      "Epoch: 2, Loss: 0.12269831448793411, Accuracy: 77.10%\n",
      "in test\n",
      "Test Accuracy: 72.48%\n",
      "out test\n",
      "3\n",
      "in train\n",
      "Epoch: 3, Loss: 0.11509065330028534, Accuracy: 79.42%\n",
      "in test\n",
      "Test Accuracy: 77.17%\n",
      "out test\n",
      "4\n",
      "in train\n",
      "Epoch: 4, Loss: 0.10999676585197449, Accuracy: 80.65%\n",
      "in test\n",
      "Test Accuracy: 82.04%\n",
      "out test\n",
      "5\n",
      "in train\n",
      "Epoch: 5, Loss: 0.10221098363399506, Accuracy: 82.54%\n",
      "in test\n",
      "Test Accuracy: 71.67%\n",
      "out test\n",
      "6\n",
      "in train\n",
      "Epoch: 6, Loss: 0.09688196331262589, Accuracy: 83.58%\n",
      "in test\n",
      "Test Accuracy: 76.17%\n",
      "out test\n",
      "7\n",
      "in train\n",
      "Epoch: 7, Loss: 0.0921986922621727, Accuracy: 84.13%\n",
      "in test\n",
      "Test Accuracy: 83.23%\n",
      "out test\n",
      "8\n",
      "in train\n",
      "Epoch: 8, Loss: 0.08850770443677902, Accuracy: 84.89%\n",
      "in test\n",
      "Test Accuracy: 68.23%\n",
      "out test\n",
      "9\n",
      "in train\n",
      "Epoch: 9, Loss: 0.08478092402219772, Accuracy: 85.88%\n",
      "in test\n",
      "Test Accuracy: 83.62%\n",
      "out test\n",
      "10\n",
      "in train\n",
      "Epoch: 10, Loss: 0.08044611662626266, Accuracy: 86.63%\n",
      "in test\n",
      "Test Accuracy: 81.29%\n",
      "out test\n",
      "11\n",
      "in train\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m loader_test\u001b[39m=\u001b[39mDataLoader(dataset\u001b[39m=\u001b[39mdataset_test,batch_size\u001b[39m=\u001b[39mbatch_size,shuffle\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n\u001b[1;32m     16\u001b[0m neural_network \u001b[39m=\u001b[39m ResNet_18()\n\u001b[0;32m---> 17\u001b[0m relu_train,relu_test\u001b[39m=\u001b[39m train_and_test(ResNet_18, loader_train,loader_valid)\n",
      "Cell \u001b[0;32mIn[7], line 28\u001b[0m, in \u001b[0;36mtrain_and_test\u001b[0;34m(model, loader_train, loader_test)\u001b[0m\n\u001b[1;32m     26\u001b[0m mono_loss \u001b[39m=\u001b[39m loss(pred_y, label)\n\u001b[1;32m     27\u001b[0m all_loss \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m mono_loss\n\u001b[0;32m---> 28\u001b[0m mono_acc \u001b[39m=\u001b[39m evaluate(pred_y, label)\n\u001b[1;32m     29\u001b[0m all_acc \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m mono_acc\n\u001b[1;32m     30\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "Cell \u001b[0;32mIn[8], line 4\u001b[0m, in \u001b[0;36mevaluate\u001b[0;34m(pred_y, label)\u001b[0m\n\u001b[1;32m      2\u001b[0m pred_y \u001b[39m=\u001b[39m pred_y\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      3\u001b[0m label \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m----> 4\u001b[0m correct \u001b[39m=\u001b[39m pred_y\u001b[39m.\u001b[39;49mmax(dim\u001b[39m=\u001b[39;49m\u001b[39m1\u001b[39;49m)[\u001b[39m1\u001b[39;49m]\u001b[39m.\u001b[39;49meq(label)\u001b[39m.\u001b[39;49msum()\u001b[39m.\u001b[39;49mitem()\n\u001b[1;32m      5\u001b[0m total \u001b[39m=\u001b[39m label\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m accuracy \u001b[39m=\u001b[39m (correct \u001b[39m/\u001b[39m total) \u001b[39m*\u001b[39m \u001b[39m100\u001b[39m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
    "if __name__ == \"__main__\":\n",
    "    batch_size = 4\n",
    "    sampler = SubsetRandomSampler(range(1000))\n",
    "    dataset_train=LeukemiaLoader(root='new_dataset/train/',mode='train')\n",
    "    loader_train=DataLoader(dataset=dataset_train,sampler = sampler, batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "    #img, label, path = dataset_train.__getitem__(0)\n",
    "    #print(path)\n",
    "    #print(img[0])\n",
    "    dataset_valid=LeukemiaLoader(root='new_dataset/valid/',mode='valid')\n",
    "    loader_valid=DataLoader(dataset=dataset_valid,sampler = sampler, batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "\n",
    "    dataset_test=LeukemiaLoader(root='new_dataset/test/',mode='test')\n",
    "    loader_test=DataLoader(dataset=dataset_test,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "    \n",
    "    neural_network_18 = ResNet_18()\n",
    "    res18_train,res18_test= train_and_test(ResNet_18, loader_train,loader_valid)\n",
    "\n",
    "    neural_network_50 = ResNet_50()\n",
    "    res50_train,res50_test= train_and_test(ResNet_50, loader_train,loader_valid)\n",
    "\n",
    "    neural_network_152 = ResNet_152()\n",
    "    res152_train,res152_test= train_and_test(ResNet_152, loader_train,loader_valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693ec800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd99857",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
