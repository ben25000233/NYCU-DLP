{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2bf76e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import LeukemiaLoader\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "print(torch.cuda.is_available())\n",
    "device=torch.device('cuda',0)\n",
    "from torch.utils.data import Dataset,DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms,models\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import copy\n",
    "import csv\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import matplotlib.colors as mcolors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a12ceee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 12\n",
    "\n",
    "dataset_train=LeukemiaLoader(root='new_dataset/train/',mode='train')\n",
    "loader_train=DataLoader(dataset=dataset_train, batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "\n",
    "dataset_valid=LeukemiaLoader(root='new_dataset/valid/',mode='valid')\n",
    "loader_valid=DataLoader(dataset=dataset_valid,batch_size=batch_size,shuffle=False,num_workers=4)\n",
    "\n",
    "dataset_test=LeukemiaLoader(root='new_dataset/test/',mode='test18')\n",
    "loader_test=DataLoader(dataset=dataset_test,batch_size=1,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21c3e577",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res18_basic_Block(nn.Module):\n",
    "    def __init__(self, inchannel, outchannel, stride = 1):\n",
    "        super(Res18_basic_Block, self).__init__()\n",
    "        \n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=3, stride=stride, padding=1),\n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(outchannel)\n",
    "        )\n",
    "        \n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or inchannel != outchannel:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(outchannel)\n",
    "            )\n",
    "            \n",
    "    def forward(self, x):\n",
    "        \n",
    "        out = self.basic(x)\n",
    "        out = out + self.shortcut(x)\n",
    "        out = nn.ReLU()(out)\n",
    "        \n",
    "        return out\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac8b8791",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Bottleneck(nn.Module):\n",
    "    \n",
    "    def __init__(self, inchannel, outchannel, stride=1, downsample=None):\n",
    "        super(Bottleneck, self).__init__()\n",
    "        self.expansion = 4\n",
    "        self.basic = nn.Sequential(\n",
    "            nn.Conv2d(inchannel, outchannel, kernel_size=1, stride=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),  \n",
    "            nn.Conv2d(outchannel, outchannel, kernel_size=3, stride=stride, padding=1),  \n",
    "            nn.BatchNorm2d(outchannel),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(outchannel, outchannel * self.expansion, kernel_size=1, stride=1),   \n",
    "            nn.BatchNorm2d(outchannel * self.expansion)\n",
    "        )\n",
    "         \n",
    "        self.downsample = downsample\n",
    "        \n",
    "    def forward(self, x):\n",
    "        identity = x\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "    \n",
    "        out = self.basic(x)\n",
    "\n",
    "        out += identity\n",
    "        out = nn.ReLU()(out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb2942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_18(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_18, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.layer1 = self.make_layer(64, 2, stride=1)\n",
    "        self.layer2 = self.make_layer(128, 2, stride=2)\n",
    "        self.layer3 = self.make_layer(256, 2, stride=2)        \n",
    "        self.layer4 = self.make_layer(512, 2, stride=2)  \n",
    "        self.classify = nn.Linear(512, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self, channel, num_blocks, stride):\n",
    "        \n",
    "        strides = [stride] + [1]\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(Res18_basic_Block(self.inchannel, channel, stride))\n",
    "            self.inchannel = channel\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6177735",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_50(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_50, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,4,6,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca19448",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet_152(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ResNet_152, self).__init__()\n",
    "        self.inchannel = 64\n",
    "        self.expansion = 4\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        )\n",
    "        self.num = [3,8,36,3]\n",
    "        self.layer1 = self.make_layer(64, self.num[0], stride=1)\n",
    "        self.layer2 = self.make_layer(128, self.num[1], stride=2)\n",
    "        self.layer3 = self.make_layer(256, self.num[2], stride=2)        \n",
    "        self.layer4 = self.make_layer(512, self.num[3], stride=2)  \n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.classify = nn.Linear(512*4, 2)\n",
    "            \n",
    "       \n",
    "    def make_layer(self,channel, num_blocks, stride):\n",
    "        \n",
    "        downsample = None\n",
    "        if stride != 1 or self.inchannel != channel * self.expansion:\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(self.inchannel, channel * self.expansion, 1,stride),\n",
    "                nn.BatchNorm2d(channel * self.expansion)\n",
    "            )\n",
    "            \n",
    "        layers = []\n",
    "        layers.append(Bottleneck(self.inchannel, channel, downsample=downsample, stride=stride)) \n",
    "        self.inchannel = channel*self.expansion   \n",
    "\n",
    "        for _ in range(1, num_blocks):  \n",
    "            layers.append(Bottleneck(self.inchannel,channel))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.conv1(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.layer4(out)\n",
    "        out = nn.AdaptiveAvgPool2d((1, 1))(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        out = self.classify(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb79ecb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(pred_y, label):\n",
    "    pred_y = pred_y.to(device)\n",
    "    label = label.to(device)\n",
    "    correct = pred_y.max(dim=1)[1].eq(label).sum().item()\n",
    "    total = label.shape[0]\n",
    "    accuracy = (correct / total) * 100\n",
    "    return accuracy\n",
    "\n",
    "def get_data(name):\n",
    "    f = open(name,'r')\n",
    "    line = f.readline()\n",
    "    line = line[1: -1]\n",
    "    temp = list(line.split(\", \"))\n",
    "    output = []\n",
    "    for i in range(1, 51):\n",
    "        output.append(float(temp[i]))\n",
    "    return output\n",
    "\n",
    "def plot(a,b,c,d,e,f):\n",
    "    epoch_list = []\n",
    "    for i in range(len(a)):\n",
    "        epoch_list.append(i)\n",
    "\n",
    "    plt.plot(epoch_list, a, label= \"res18_train\")\n",
    "    plt.plot(epoch_list, b, label= \"res18_test\")\n",
    "    plt.plot(epoch_list, c, label= \"res50_train\")\n",
    "    plt.plot(epoch_list, d, label= \"res50_test\")\n",
    "    plt.plot(epoch_list, e, label= \"res152_train\")\n",
    "    plt.plot(epoch_list, f, label= \"res152_test\")\n",
    "    plt.ylim(50, 100)\n",
    "    plt.legend(loc = 4)\n",
    "    plt.show()\n",
    "\n",
    "def plot_confusion_matrix(pred_y, label):\n",
    "\n",
    "    cm = confusion_matrix(label, pred_y)\n",
    "    colors = ['white', '#b4c7e7', '#8caad9', '#5a8ed0', '#1974c7']\n",
    "    cmap = mcolors.ListedColormap(colors)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    classes = [0, 1] \n",
    "    tick_marks = np.arange(2)\n",
    "    plt.xticks(tick_marks, classes)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    thresh = cm.max() / 2.\n",
    "    for i in range(cm.shape[0]):\n",
    "        for j in range(cm.shape[1]):\n",
    "            plt.text(j, i, format(cm[i, j]),\n",
    "                     horizontalalignment=\"center\",\n",
    "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    plt.xlabel('Predicted Label')\n",
    "    plt.ylabel('True Label')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4fa82a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, loader_train, optimizer, loss_fn):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    counter = 0\n",
    "    for idx,(data,label, path) in enumerate(loader_train):\n",
    "        data = data.to(device, dtype=torch.float)\n",
    "        label = label.to(device, dtype=torch.long)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        pred_y = model(data)\n",
    "        mono_loss = loss_fn(pred_y, label)\n",
    "        mono_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += mono_loss\n",
    "        mono_acc = evaluate(pred_y, label)\n",
    "        total_correct += mono_acc\n",
    "        counter+=1\n",
    "\n",
    "    train_loss = total_loss / len(loader_train.dataset)\n",
    "    train_accuracy = total_correct / counter\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "def validate(model, loader_test, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    total_correct = 0\n",
    "    total_samples = 0\n",
    "    counter = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,(data,label, path) in enumerate(loader_test):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            label = label.to(device, dtype=torch.long)\n",
    "\n",
    "            pred_y = model(data)\n",
    "            mono_loss = loss_fn(pred_y, label)\n",
    "\n",
    "            total_loss += mono_loss\n",
    "            mono_acc = evaluate(pred_y, label)\n",
    "            total_correct += mono_acc\n",
    "            counter+=1\n",
    "\n",
    "    test_loss = total_loss / len(loader_test.dataset)\n",
    "    test_accuracy = total_correct / counter\n",
    "    return test_loss, test_accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3319c679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_test(model, loader_train,loader_test): \n",
    "\n",
    "    model.to(device)\n",
    "    lr = 1e-2\n",
    "    loss_fn = torch.nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.RAdam(model.parameters(), lr=lr)\n",
    "    scheduler = StepLR(optimizer, step_size=3, gamma=0.5)\n",
    "    best_acc = 0\n",
    "    best_model_wts=None\n",
    "    total_train = [0]\n",
    "    total_test = [0]\n",
    "    epochs = 50\n",
    "    \n",
    "\n",
    "    for epoch in range(1, epochs + 1):\n",
    "        train_loss, train_accuracy = train(model, loader_train, optimizer, loss_fn)\n",
    "        total_train.append(train_accuracy)\n",
    "        test_loss, test_accuracy = validate(model, loader_test, loss_fn)\n",
    "        total_test.append(test_accuracy)\n",
    "        print(f\"Epoch {epoch}\")\n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%\")\n",
    "        print(f\"Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%\")\n",
    "        if test_accuracy>best_acc:\n",
    "            best_evaluated_acc = test_accuracy\n",
    "            best_model_wts=copy.deepcopy(model.state_dict())\n",
    "            #FILE = 'temp_weight.pt'\n",
    "            #torch.save(best_model_wts,FILE)\n",
    "        scheduler.step()\n",
    "    \n",
    "    return total_train, total_test, best_model_wts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9adca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_data, weights_path):\n",
    "    weight_file = weights_path\n",
    "    model.load_state_dict(torch.load(weight_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    result = []\n",
    "\n",
    "\n",
    "    with open('result.csv', 'w', newline='') as csvfile:\n",
    "       writer = csv.writer(csvfile)\n",
    "       writer.writerow(['ID', 'label'])\n",
    "       with torch.no_grad():\n",
    "           for idx,(data, path) in enumerate(test_data):\n",
    "               data = data.to(device, dtype=torch.float)\n",
    "               pred_y = model(data)\n",
    "               outputs = pred_y.max(dim=1)[1]\n",
    "               output = outputs.tolist()\n",
    "               path = \".\"+str(path)[2:-3]\n",
    "               writer.writerow([path, output[0]])\n",
    "               result += output   \n",
    "    \n",
    "    return result\n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b11af1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tv_test(model, loader_test, weights_path):\n",
    "    weight_file = weights_path\n",
    "    model.load_state_dict(torch.load(weight_file))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    result = []\n",
    "    labels = []\n",
    "    acc = 0\n",
    "    with torch.no_grad():\n",
    "        for idx,(data, label, path) in tqdm(enumerate(loader_test), total = len(loader_test)):\n",
    "            data = data.to(device, dtype=torch.float)\n",
    "            pred_y = model(data)\n",
    "            outputs = pred_y.max(dim=1)[1]\n",
    "            output = outputs.tolist()\n",
    "            result += output  \n",
    "            label = label.tolist()\n",
    "            labels += label\n",
    "            if output == label :\n",
    "                acc += 1\n",
    "        acc /= len(loader_test)\n",
    "    return labels, result, acc\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b337fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    action = \"load\"\n",
    "    #training model and record\n",
    "    \n",
    "    if action == \"train\":\n",
    "        neural_network_18 = ResNet_18()\n",
    "        res18_train,res18_test, res18_weights= train_and_test(neural_network_18, loader_train,loader_valid)\n",
    "        print(f\"resnet18 max acc：{max(res18_train)}\")\n",
    "        print(f\"resnet18_test max acc：{max(res18_test)}\")\n",
    "        FILE = 'resnet_18_all_state_dict.pt'\n",
    "        torch.save(res18_weights,FILE)\n",
    "        \n",
    "        a = str(res18_train)\n",
    "        b = str(res18_test)\n",
    "        f = open('resnet18_train.txt','w')\n",
    "        f.write(a)\n",
    "        f.close()\n",
    "        f = open('resnet18_test.txt','w')\n",
    "        f.write(b)\n",
    "        f.close()\n",
    "        \n",
    "        neural_network_50 = ResNet_50()\n",
    "        res50_train,res50_test, res50_weights= train_and_test(neural_network_50, loader_train,loader_valid)\n",
    "        print(f\"resnet50_train max acc：{max(res50_train)}\")\n",
    "        print(f\"resnet50_test max acc：{max(res50_test)}\")\n",
    "        FILE = 'resnet_50_all_state_dict.pt'\n",
    "        torch.save(res50_weights,FILE)\n",
    "        a = str(res50_train)\n",
    "        b = str(res50_test)\n",
    "        f = open('resnet50_train.txt','w')\n",
    "        f.write(a)\n",
    "        f.close()\n",
    "        f = open('resnet50_test.txt','w')\n",
    "        f.write(b)\n",
    "        f.close()\n",
    "        \n",
    "        neural_network_152 = ResNet_152()\n",
    "        res152_train,res152_test, res152_weights= train_and_test(neural_network_152, loader_train,loader_valid)\n",
    "        print(f\"resnet152_train max acc：{max(res152_train)}\")\n",
    "        print(f\"resnet152_test max acc：{max(res152_test)}\")\n",
    "        FILE = 'resnet_152_all_state_dict.pt'\n",
    "        torch.save(res152_weights,FILE)\n",
    "        a = str(res152_train)\n",
    "        b = str(res152_test)\n",
    "        f = open('resnet152_train.txt','w')\n",
    "        f.write(a)\n",
    "        f.close()\n",
    "        f = open('resnet152_test.txt','w')\n",
    "        f.write(b)\n",
    "        f.close()\n",
    "        \n",
    "        train18 = get_data(\"resnet18_train.txt\")\n",
    "        test18 = get_data(\"resnet18_test.txt\")\n",
    "        train50 = get_data(\"resnet50_train.txt\")\n",
    "        test50 = get_data(\"resnet50_test.txt\")\n",
    "        train152 = get_data(\"resnet152_train.txt\")\n",
    "        test152 = get_data(\"resnet152_test.txt\")\n",
    "        plot(train18, test18, train50, test50, train152, test152)\n",
    "\n",
    "    elif action == \"pridict\":\n",
    "        #predict and write csv\n",
    "        res18 = ResNet_18()\n",
    "        result = test(res18, loader_test, 'resnet18_weight.pt')\n",
    "\n",
    "        res50 = ResNet_50()\n",
    "        result = test(res18, loader_test, 'resnet50_weight.pt')\n",
    "\n",
    "        res152 = ResNet_152()\n",
    "        result = test(res152, loader_test, 'resnet152_weight.pt')\n",
    "\n",
    "    elif action == \"load\":\n",
    "        #load model weight and plot confusion matrix\n",
    "\n",
    "        dataset_train=LeukemiaLoader(root='new_dataset/train/',mode='train')\n",
    "        loader_train=DataLoader(dataset=dataset_train, batch_size=1,shuffle=False,num_workers=4)\n",
    "\n",
    "        neural_network_18 = ResNet_18()\n",
    "        labels, result , acc = tv_test(neural_network_18, loader_train, \"resnet18_weight.pt\")\n",
    "        print(\"RestNet18 acc: \", acc)\n",
    "        plot_confusion_matrix(labels, result)\n",
    "\n",
    "        neural_network_50 = ResNet_50()\n",
    "        labels, result , acc= tv_test(neural_network_50, loader_train, \"resnet50_weight.pt\")\n",
    "        print(\"RestNet50 acc: \", acc)\n",
    "        plot_confusion_matrix(labels, result)\n",
    "\n",
    "        neural_network_152 = ResNet_152()\n",
    "        labels, result , acc= tv_test(neural_network_152, loader_train, \"resnet152_weight.pt\")\n",
    "        print(\"RestNet152 acc: \", acc)\n",
    "        plot_confusion_matrix(labels, result)\n",
    "    \n",
    "    else : \n",
    "        print(\"wrong action\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
