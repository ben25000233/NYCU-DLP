{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "94858c82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import DataLoader,TensorDataset\n",
    "device=torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(device)\n",
    "print(torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d084f84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_bci_data():\n",
    "    S4b_train = np.load('S4b_train.npz')\n",
    "    X11b_train = np.load('X11b_train.npz')\n",
    "    S4b_test = np.load('S4b_test.npz')\n",
    "    X11b_test = np.load('X11b_test.npz')\n",
    "\n",
    "    train_data = np.concatenate((S4b_train['signal'], X11b_train['signal']), axis=0)\n",
    "    train_label = np.concatenate((S4b_train['label'], X11b_train['label']), axis=0)\n",
    "    test_data = np.concatenate((S4b_test['signal'], X11b_test['signal']), axis=0)\n",
    "    test_label = np.concatenate((S4b_test['label'], X11b_test['label']), axis=0)\n",
    "\n",
    "\n",
    "    train_label = train_label - 1\n",
    "    test_label = test_label -1\n",
    "    train_data = np.transpose(np.expand_dims(train_data, axis=1), (0, 1, 3, 2))\n",
    "    test_data = np.transpose(np.expand_dims(test_data, axis=1), (0, 1, 3, 2))\n",
    "   \n",
    "\n",
    "    mask = np.where(np.isnan(train_data))\n",
    "    train_data[mask] = np.nanmean(train_data)\n",
    "\n",
    "    mask = np.where(np.isnan(test_data))\n",
    "    test_data[mask] = np.nanmean(test_data)\n",
    "\n",
    "   \n",
    "\n",
    "    return train_data, train_label, test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54d128b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<torch.utils.data.dataloader.DataLoader object at 0x000002A13CE13910>\n"
     ]
    }
   ],
   "source": [
    "train_data, train_label, test_data, test_label = read_bci_data()\n",
    "dataset = TensorDataset(torch.from_numpy(train_data),torch.from_numpy(train_label))\n",
    "loader_train = DataLoader(dataset,batch_size=256,shuffle=True,num_workers=4)\n",
    "print(loader_train)\n",
    "dataset = TensorDataset(torch.from_numpy(test_data),torch.from_numpy(test_label))\n",
    "loader_test = DataLoader(dataset,batch_size=256,shuffle=False,num_workers=4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "da2207eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EEGNet(nn.Module):\n",
    "    def __init__(self,activation=nn.ELU()):\n",
    "        super(EEGNet,self).__init__()\n",
    "        self.firstconv=nn.Sequential(\n",
    "            nn.Conv2d(1,16,kernel_size=(1,51),stride=(1,1),padding=(0,25),bias=False),\n",
    "            nn.BatchNorm2d(16,eps=1e-5,momentum=0.1,affine=True,track_running_stats=True)\n",
    "        )\n",
    "        self.depthwiseConv=nn.Sequential(\n",
    "            nn.Conv2d(16,32,kernel_size=(2,1),stride=(1,1),groups=16,bias=False),\n",
    "            nn.BatchNorm2d(32,eps=1e-5,momentum=0.1,affine=True,track_running_stats=True),\n",
    "            activation,\n",
    "            nn.AvgPool2d(kernel_size=(1,4),stride=(1,4),padding=0),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        self.seperableConv=nn.Sequential(\n",
    "            nn.Conv2d(32,32,kernel_size=(1,15),stride=(1,1),padding=(0,7),bias=False),\n",
    "            nn.BatchNorm2d(32,eps=1e-5,momentum=0.1,affine=True,track_running_stats=True),\n",
    "            activation,\n",
    "            nn.AvgPool2d(kernel_size=(1,8),stride=(1,8),padding=0),\n",
    "            nn.Dropout(p=0.25)\n",
    "        )\n",
    "        self.classify=nn.Linear(736,2)\n",
    "    def forward(self,inputs):\n",
    "        output = self.firstconv(inputs)\n",
    "        output = self.depthwiseConv(output)\n",
    "        output = self.seperableConv(output)\n",
    "        output = torch.flatten(output, start_dim=1)\n",
    "        return self.classify(output)\n",
    "    \n",
    "    def calculate_accuracy(self, pred_y, label):\n",
    "        correct = pred_y.max(dim=1)[1].eq(label).sum().item()\n",
    "        total = len(label)\n",
    "        accuracy = (correct / total) * 100\n",
    "        return accuracy\n",
    "    \n",
    "    \n",
    "    def train_and_test(self, loader_train,loader_test):\n",
    "        batch_size= 64        \n",
    "        lr = 1e-2        \n",
    "        activations={nn.ReLU(),nn.LeakyReLU(),nn.ELU()}\n",
    "        loss = torch.nn.CrossEntropyLoss()\n",
    "        train_acc = []\n",
    "        \n",
    "        for act in activations:\n",
    "            model=EEGNet(act)\n",
    "            model.to(device)\n",
    "            optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "            for epoch in range(150):\n",
    "                model.train()\n",
    "                all_loss = 0\n",
    "                print(epoch)\n",
    "                for idx,(data,label) in enumerate(loader_train):\n",
    "                    data=data.to(device,dtype=torch.float)\n",
    "                    label=label.to(device,dtype=torch.long)\n",
    "                    pred_y = model(data)\n",
    "                    mono_loss = loss(pred_y, label)\n",
    "                    all_loss += mono_loss\n",
    "                    accuracy = self.calculate_accuracy(pred_y, label)\n",
    "                    if epoch % 5 == 0:\n",
    "                        print(f\"Epoch: {epoch}, Loss: {all_loss/len(loader_train.dataset)}, Accuracy: {accuracy:.2f}%\")\n",
    "                    optimizer.zero_grad()\n",
    "                    mono_loss.backward() \n",
    "                    optimizer.step()    \n",
    "            print(\"Training finished.\")\n",
    "        print('start testing:')\n",
    "        model.eval()\n",
    "        for index, data in enumerate(test_data):\n",
    "            predict = model(data)\n",
    "            loss = loss(test_label, predict)\n",
    "            accuracy = self.calculate_accuracy(pred_y, test_label)\n",
    "        print(f\"Loss: {np.mean(loss)}, Accuracy: {accuracy:.2f}%\")\n",
    "        print('testing finished')\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eed24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "Epoch: 0, Loss: 0.0007093040621839464, Accuracy: 43.75%\n",
      "Epoch: 0, Loss: 0.0013329839566722512, Accuracy: 60.16%\n",
      "Epoch: 0, Loss: 0.0018630385166034102, Accuracy: 73.05%\n",
      "Epoch: 0, Loss: 0.0024113778490573168, Accuracy: 74.22%\n",
      "Epoch: 0, Loss: 0.0033081313595175743, Accuracy: 69.64%\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "Epoch: 5, Loss: 0.00045142779708839953, Accuracy: 73.44%\n",
      "Epoch: 5, Loss: 0.0008849237347021699, Accuracy: 74.22%\n",
      "Epoch: 5, Loss: 0.001379515277221799, Accuracy: 70.31%\n",
      "Epoch: 5, Loss: 0.0018725770059973001, Accuracy: 74.61%\n",
      "Epoch: 5, Loss: 0.002175818430259824, Accuracy: 89.29%\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "Epoch: 10, Loss: 0.00043485360220074654, Accuracy: 74.22%\n",
      "Epoch: 10, Loss: 0.0008680610335431993, Accuracy: 77.34%\n",
      "Epoch: 10, Loss: 0.001254543662071228, Accuracy: 78.52%\n",
      "Epoch: 10, Loss: 0.0017235722625628114, Accuracy: 73.83%\n",
      "Epoch: 10, Loss: 0.0021188193932175636, Accuracy: 75.00%\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "Epoch: 15, Loss: 0.0003857033443637192, Accuracy: 80.47%\n",
      "Epoch: 15, Loss: 0.0008101363200694323, Accuracy: 75.78%\n",
      "Epoch: 15, Loss: 0.0012515641283243895, Accuracy: 78.12%\n",
      "Epoch: 15, Loss: 0.0016501247882843018, Accuracy: 80.47%\n",
      "Epoch: 15, Loss: 0.0021236534230411053, Accuracy: 82.14%\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "Epoch: 20, Loss: 0.00036803909461013973, Accuracy: 82.03%\n",
      "Epoch: 20, Loss: 0.0007709122728556395, Accuracy: 79.30%\n",
      "Epoch: 20, Loss: 0.0012461923761293292, Accuracy: 76.95%\n",
      "Epoch: 20, Loss: 0.001608152873814106, Accuracy: 83.20%\n",
      "Epoch: 20, Loss: 0.0019274578662589192, Accuracy: 83.93%\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "Epoch: 25, Loss: 0.0003446477057877928, Accuracy: 83.59%\n",
      "Epoch: 25, Loss: 0.0007158184889703989, Accuracy: 82.03%\n",
      "Epoch: 25, Loss: 0.0011342769721522927, Accuracy: 78.12%\n",
      "Epoch: 25, Loss: 0.001445680158212781, Accuracy: 85.94%\n",
      "Epoch: 25, Loss: 0.001766097266227007, Accuracy: 85.71%\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "Epoch: 30, Loss: 0.00028299796395003796, Accuracy: 87.89%\n",
      "Epoch: 30, Loss: 0.000705469399690628, Accuracy: 81.25%\n",
      "Epoch: 30, Loss: 0.0010337817948311567, Accuracy: 87.11%\n",
      "Epoch: 30, Loss: 0.0012870862847194076, Accuracy: 88.67%\n",
      "Epoch: 30, Loss: 0.0016113881720229983, Accuracy: 85.71%\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "Epoch: 35, Loss: 0.0003034990222658962, Accuracy: 86.33%\n",
      "Epoch: 35, Loss: 0.0006031953380443156, Accuracy: 84.77%\n",
      "Epoch: 35, Loss: 0.000876023608725518, Accuracy: 85.94%\n",
      "Epoch: 35, Loss: 0.0011854242766276002, Accuracy: 87.11%\n",
      "Epoch: 35, Loss: 0.0013800254091620445, Accuracy: 92.86%\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "neural_network = EEGNet()\n",
    "neural_network.train_and_test(loader_train,loader_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33ceeee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "activations={nn.ReLU(),nn.LeakyReLU(),nn.ELU()}\n",
    "for activation in activations:\n",
    "    print (activation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0feb2e85",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
